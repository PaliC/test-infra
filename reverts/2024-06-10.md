# Week of 2024-06-10 to 2024-06-17 (39)

### GHFirst (18)

- [Revert "[ROCm] Unskip scaled_dot_product_attention tests on ROCm (#127966)"](https://github.com/pytorch/pytorch/commit/2367161e4bbefd45ebd507fdfc523bbf628d32a3)
  - Broke ROCm CI ([comment](https://github.com/pytorch/pytorch/pull/127966#issuecomment-2168505985))
- [Revert "[dynamo] Enable some inlining inbuilt nn module tests (#128440)"](https://github.com/pytorch/pytorch/commit/c63ccead5effbacfa40db14f11b63b16d3996aaf)
  - new test broke internally D58501220 ([comment](https://github.com/pytorch/pytorch/pull/128440#issuecomment-2166127531))
- [Revert "[cuDNN][SDPA] Remove `TORCH_CUDNN_SDPA_ENABLED=1`, enable cuDNN SDPA by default on H100 and 2nd on other archs >= sm80 (#125343)"](https://github.com/pytorch/pytorch/commit/817ce6835b3c640c770cf6c19ab8e64fc2e937de)
  - The above revert PR can't be merged since the bot that made the original commit can't sign the CLA, so I'm rerverting this way instead, I will defer to elias for repro instructions and debugging info ([comment](https://github.com/pytorch/pytorch/pull/125343#issuecomment-2163690162))
- [Revert "[cuDNN][SDPA] Support different key, value dimension in cuDNN SDPA (#128350)"](https://github.com/pytorch/pytorch/commit/7db501ba2b1bf3d3b61c3fada92d424a2f571683)
  - Sorry have to revert this in order to revert #125343 ([comment](https://github.com/pytorch/pytorch/pull/128350#issuecomment-2163669538))
- [Revert "Make TraceUtils.h to be device-agnostic (#126969)"](https://github.com/pytorch/pytorch/commit/5001f41b9047dfb8d97a63fd20d53a80b2706537)
  - failing internal builds D58443769 ([comment](https://github.com/pytorch/pytorch/pull/126969#issuecomment-2163462600))
- [Revert "Pass params to dump_nccl_trace_pickle (#128307)"](https://github.com/pytorch/pytorch/commit/f89574fa2376e53031a582d0a9ab8a49772ae46c)
  - sorry need to revert this in order to revert 126969 ([comment](https://github.com/pytorch/pytorch/pull/128307#issuecomment-2163459399))
- [Revert "Support aten operations with out tensor (#124926)"](https://github.com/pytorch/pytorch/commit/81e4e12f02618777ba8784c3e91e33d48ab3dfca)
  - newly added test broke in internal D58444103.  Test passed in OSS CI though, I think this needs a targets file change? Edit: nvm other tests fail with similar reasons, this is not unique to the added test, I will remerge ([comment](https://github.com/pytorch/pytorch/pull/124926#issuecomment-2163441547))
- [Revert "[AOTI] Switch to use shim v2 (#127674)"](https://github.com/pytorch/pytorch/commit/c5172b8de851c0c534c415aac51c381950eb2905)
  - tests failed internally D56709309 ([comment](https://github.com/pytorch/pytorch/pull/127674#issuecomment-2163436728))
- [Revert "Prevent expansion of cat indexing to avoid int64 intermediate (#127815)"](https://github.com/pytorch/pytorch/commit/f2dcbe89d6613d211ff8a053b1e5f4b1f7f92952)
  - the newly added test is failing internally D58444153.  Test exists in opensource and passed in OSS CI.  Logs make me think it just wants better hardware, I think its running on a v100 internally https://www.internalfb.com/code/fbsource/[7cdd1174964c26145eb8274ba3625ba0d69bc39e]/fbcode/caffe2/test/inductor/TARGETS?lines=25 ([comment](https://github.com/pytorch/pytorch/pull/127815#issuecomment-2163421968))
- [Revert "Fix side effect pruning (#128028)"](https://github.com/pytorch/pytorch/commit/15ab636007223803b7d77c14b881ea337ce75a32)
  - broke test in internal D58443816.  Test exists in external but isn't run because we don't install torchrec ([comment](https://github.com/pytorch/pytorch/pull/128028#issuecomment-2163249251))
- [Revert "Introduce int_oo (#127693)"](https://github.com/pytorch/pytorch/commit/5d8c7f39d46699d8f8e92512309ea3499a29c08a)
  - sorry executorch CI is a bit weird regarding pins, I'll make a chat with mergen with the choices of what to do and how it'll affect executorch CI, reverting for now to prevent more divergences in the meantime ([comment](https://github.com/pytorch/pytorch/pull/127693#issuecomment-2161775400))
- [Revert "Flip default value for mypy disallow_untyped_defs [10+2/11] (#128374)"](https://github.com/pytorch/pytorch/commit/c9c1fed06549c7a0e7eb69f3aa8220c9e24f7629)
  - sorry I need to revert this in order to revert something else, to remerge, just rebase and fix the merge conflict ([comment](https://github.com/pytorch/pytorch/pull/128374#issuecomment-2161772864))
- [Revert "[RELAND][dynamo][nn-modules] Trace through nn.Module dunder methods for UnspecializedNNModule (#126578)"](https://github.com/pytorch/pytorch/commit/adb699189b9d2de7cfbd71e59c70d916483b23dd)
  - failed internal test D58394084.  Author has forward fix but includes external changes so reverting is a bit easier to coordinate ([comment](https://github.com/pytorch/pytorch/pull/126578#issuecomment-2161481839))
- [Revert "Make nn.Module state_dict load_state_dict pre-hook and state_dict post hook public (#126704)"](https://github.com/pytorch/pytorch/commit/1d233b8f500f3fafb96e944953579a33a3c1c24e)
  - broke internal typecheck D58394110 (which probably means the code wouldn't work either but I guess it didn't run on the diff). Probably an easy fix? ([comment](https://github.com/pytorch/pytorch/pull/126704#issuecomment-2161299193))
- [Revert "Make sure #126704 is BC for torch.save-ed `nn.Module` (#128344)"](https://github.com/pytorch/pytorch/commit/491c4a5dcbad4a5cea1735cd42072766827ab5b0)
  - broke internal typecheck D58394110 (which probably means the code wouldn't work either but I guess it didn't run on the diff). Probably an easy fix? ([comment](https://github.com/pytorch/pytorch/pull/126704#issuecomment-2161299193))
- [Revert "Deprecate `torch._utils.is_compiling()` and `torch._dynamo.external_utils.is_compiling()` (#127690)"](https://github.com/pytorch/pytorch/commit/90bb510ece29ff505fe8fdf13220e622485a8e9b)
  - sorry I think https://github.com/pytorch/pytorch/pull/126898#issuecomment-2142884456 is still relevant, I will reach out to them to see what needs to be done in internal to get this remerged D58333868 ([comment](https://github.com/pytorch/pytorch/pull/127690#issuecomment-2159248859))
- [Revert "Fix 'get_attr' call in dynamo 'run_node' (#127696)"](https://github.com/pytorch/pytorch/commit/ca561d639b40a9fce088262e2fb35c7dfb61d588)
  - broke (executorch?) internal tests D58295865 ([comment](https://github.com/pytorch/pytorch/pull/127696#issuecomment-2158820093))
- [Revert "Fix 'get_real_value' on placeholder nodes (#127698)"](https://github.com/pytorch/pytorch/commit/d22287d1ad3406a547a150b9504ae762e175f8f1)
  - broke (executorch?) internal tests D58295865 ([comment](https://github.com/pytorch/pytorch/pull/127696#issuecomment-2158820093))

### Ignored Signal (2)

- [Revert "First version of AOTAutogradCache (#126791)"](https://github.com/pytorch/pytorch/commit/71f491554c182e78c59ac6ed3e35ae9efefc7b1e)
  - The changes broke a number of linux jobs ([comment](https://github.com/pytorch/pytorch/pull/126791#issuecomment-2163081643))
- [Revert "Add OpInfo entry for alias_copy (#127232) (#128142)"](https://github.com/pytorch/pytorch/commit/3b73f5de3a022b423a2a90fbdd9109997474b155)
  - The changes broke the test_output_match_alias_copy_cpu_complex64 test. ([comment](https://github.com/pytorch/pytorch/pull/128142#issuecomment-2158793878))

### Landrace (4)

- [Revert "[export] Add print_readable to unflattener (#128617)"](https://github.com/pytorch/pytorch/commit/5efe71f1345a38e102971d68df5f2e985a1daf7c)
  - Sorry for reverting your change but another failed test shows up in trunk inductor/test_flex_attention.py where it needs to be updated https://hud.pytorch.org/pytorch/pytorch/commit/5d9a609b4f6c94fb930188e4d7c99f53d989c022.  I guess it is easier to revert and reland this ([comment](https://github.com/pytorch/pytorch/pull/128617#issuecomment-2169030779))
- [Revert "Extended Module Tracker (#128508)"](https://github.com/pytorch/pytorch/commit/f75f5987aa9a457e8493d910e0f2901e107a0ebf)
  - Broke lint, see https://github.com/pytorch/pytorch/actions/runs/9515753429/job/26230639980 ([comment](https://github.com/pytorch/pytorch/pull/128508#issuecomment-2168405784))
- [Revert "Run all samples for torchinductor tests (#128343)"](https://github.com/pytorch/pytorch/commit/18f35d9e12ba3b9c6e76e50dd25938e5ce01294e)
  - broke inductor/test_torchinductor_opinfo.py::TestInductorOpInfoCUDA::test_comprehensive_nn_functional_avg_pool3d_cuda_float16 and other tests https://hud.pytorch.org/pytorch/pytorch/commit/41df20c07caecddb6d21d69a125f2998ae9313e8 https://github.com/pytorch/pytorch/actions/runs/9509191526/job/26213490266. I think this might be a landrace ([comment](https://github.com/pytorch/pytorch/pull/128343#issuecomment-2167275337))
- [Revert "[cuDNN][Quantization] Don't print when plan finalization fails in cuDNN quantization backend (#128177)"](https://github.com/pytorch/pytorch/commit/3ddec713b81c671cdeec5d59b7b8f554ca684fc0)
  - broke test/test_quantization.py::TestQuantizedLinear::test_qlinear_cudnn on sm86 tests https://hud.pytorch.org/pytorch/pytorch/commit/cac7a22b92478d897488688010e562b7bd36b97f https://github.com/pytorch/pytorch/actions/runs/9470648757/job/26100448913.  Probably a landrace, test ran on the PR and succeed ([comment](https://github.com/pytorch/pytorch/pull/128177#issuecomment-2161977110))

### Not through pytorchbot (3)

- [Revert D56709309 (#128481)](https://github.com/pytorch/pytorch/commit/c76a9d13cb5afb4a9b45bc2e83e049f44ccf40e9)
- [Revert "Make torch_geometric models compatible with export (#123403)" (#128377)](https://github.com/pytorch/pytorch/commit/5ef70faaa76364a73cd7f9da2d3f8e23da218b02)
- [Back out "[Dynamo] Treat integers stored on nn.Modules as dynamic (#126466)" (#128432)](https://github.com/pytorch/pytorch/commit/bb2a9955297fe064b99308a64a1ac43ab1a212c8)

### No Signal (11)

- [Revert "[1/N] Change #include <c10/util/Optional.h> to #include <optional> (#128301)"](https://github.com/pytorch/pytorch/commit/846bb30e13a534b931dfc1d27e058b63aa88d90d)
  - Sorry for reverting your change but it fails XLA build https://hud.pytorch.org/pytorch/pytorch/commit/bd72e28314d8d63bb347becb8309f5ac7761c6b5. Please rebase your PR before relanding because I think the failure is hidden by an unrelated broken trunk XLA failure from your current base commit ([comment](https://github.com/pytorch/pytorch/pull/128301#issuecomment-2169035822))
- [Revert "[Port][Quant][Inductor] Bug fix: mutation nodes not handled correctly for QLinearPointwiseBinaryPT2E (#128591)"](https://github.com/pytorch/pytorch/commit/ee140a198fbe8e7edb5f51806f63e9fa80f523fe)
  - Contains release only changes should not be landed ([comment](https://github.com/pytorch/pytorch/pull/128591#issuecomment-2168308233))
- [Revert "[traced-graph][sparse] remove redundant assert in sparse prop test (#128523)"](https://github.com/pytorch/pytorch/commit/43ae3073f92c4c329b094522670a7ea677badf78)
  - Sorry for the revert. Looks like your changes broke the inductor tests: inux-jammy-cpu-py3.8-gcc11-inductor, linux-jammy-cpu-py3.8-gcc11-inductor, linux-jammy-cpu-py3.8-gcc11-inductor. [Here you can find more details](https://hud.pytorch.org/pytorch/pytorch/commit/ba3726d02b25dff92762c59d4dffe96a7babfa75). ([comment](https://github.com/pytorch/pytorch/pull/128523#issuecomment-2167518145))
- [Revert "[ONNX] Add upsample trilinear to skip decomp (#128259)"](https://github.com/pytorch/pytorch/commit/0186b386cd7bfa0c64727cc2bad9bd2bf450d025)
  - Sorry for reverting your change but its ONNX job is failing in trunk https://hud.pytorch.org/pytorch/pytorch/commit/b72989a2b5ac4637612e31e325d7c8233fcbd7a1 ([comment](https://github.com/pytorch/pytorch/pull/128259#issuecomment-2167058937))
- [Revert "[checkpoint] Clean up selective activation checkpoint and make public (#125795)"](https://github.com/pytorch/pytorch/commit/6895a5804c6ba3812379166de11f78bb4bf72515)
  - breaking torchtitan CI ([comment](https://github.com/pytorch/pytorch/pull/125795#issuecomment-2167036157))
- [Revert "Add test to xfail_list only for abi_compatible (#128506)"](https://github.com/pytorch/pytorch/commit/c8e9656a12268ea182100ac0f6bfee2dfd9a8098)
  - Sorry for reverting your change but it causes an inductor test to fail in trunk https://hud.pytorch.org/pytorch/pytorch/commit/49366b2640df1cba5a3b40bedd31b57b08529612 ([comment](https://github.com/pytorch/pytorch/pull/128506#issuecomment-2166824714))
- [Revert "[aota] compiled forward outputs requires_grad alignment with eager (#128016)"](https://github.com/pytorch/pytorch/commit/dd19c9150c4377487fbbe506a78b60c213a8cbb5)
  - fix torchbench regression ([comment](https://github.com/pytorch/pytorch/pull/128016#issuecomment-2166446841))
- [Revert "[dynamo][yolov3] Track UnspecializedNNModuleVariable for mutation (#128269)"](https://github.com/pytorch/pytorch/commit/d630e1e838e7416b6e27572a91407c4447a00734)
  - incorrect ([comment](https://github.com/pytorch/pytorch/pull/128269#issuecomment-2164267320))
- [Revert "[tp] refactor and fix PrepareModuleInput for DTensor inputs (#128431)"](https://github.com/pytorch/pytorch/commit/a42169999822b8911cd834bf18e39fb5168e6d40)
  - Sorry for the revert. Your changes broke the linter. Here you can find more details - https://hud.pytorch.org/pytorch/pytorch/commit/089f9a116ac8b2c14d6351b52614b529caba126b ([comment](https://github.com/pytorch/pytorch/pull/128431#issuecomment-2162197858))
- [Revert "Set simdlen based on ATEN_CPU_CAPABILITY (#123514)"](https://github.com/pytorch/pytorch/commit/4bbadeee8af837e95fc7742f36639a5710c38247)
  - broke test/inductor/test_torchinductor.py::CpuTests::test_new_cpp_build_logical_cpu on periodic test on the no gpu tests https://hud.pytorch.org/pytorch/pytorch/commit/b66e3f0957b96b058c9b632ca60833d9717a9d8a https://github.com/pytorch/pytorch/actions/runs/9453518547/job/26040077301 ([comment](https://github.com/pytorch/pytorch/pull/123514#issuecomment-2159433432))
- [Revert "[export] FIx unflattener for preserving modules containing unused inputs (#128260)"](https://github.com/pytorch/pytorch/commit/db2fa7b827cdc5b49d60aa094268583a2ab7cf92)
  - breaking windows test ([comment](https://github.com/pytorch/pytorch/pull/128260#issuecomment-2159050726))

### Weird (1)

- [Revert "[inductor] enable fx graph cache on torchbench (#128239)"](https://github.com/pytorch/pytorch/commit/fa88f390a04bc59aefad555b1fc631a33b42f2cb)
  - Sorry for reverting your change but it seems to surface a bunch of inductor failures in trunk https://hud.pytorch.org/pytorch/pytorch/commit/734e8f6ad7e7f0fa0341fb658f1f986225173f5f ([comment](https://github.com/pytorch/pytorch/pull/128239#issuecomment-2159789242))
