# Week of 2024-05-27 to 2024-06-03 (35)

### GHFirst (20)

- [Revert "Default XLA to use swap_tensors path in nn.Module._apply (#126814)"](https://github.com/pytorch/pytorch/commit/17dea09b15cefc9dc5ee94833f2de7947b5333d3)
  - suspicious build instructions count regression, see [D58015016](https://www.internalfb.com/diff/D58015016) ([comment](https://github.com/pytorch/pytorch/pull/126814#issuecomment-2143545818))
- [Revert "Default meta device to use swap_tensors in nn.Module._apply  (.to_empty and .to('meta')) (#126819)"](https://github.com/pytorch/pytorch/commit/82cd7a7dab91a0d8fe189ebab89d1fc40192077f)
  - suspicious build instructions count regression, see [D58015016](https://www.internalfb.com/diff/D58015016) ([comment](https://github.com/pytorch/pytorch/pull/126814#issuecomment-2143545818))
- [Revert "[easy?] Move AsyncCompile to a different file (#127235)"](https://github.com/pytorch/pytorch/commit/22f392ba408f71a15af46847cddc6e1cf9ce86fb)
  - breaking internal tests, see [D58015187](https://www.internalfb.com/diff/D58015187) ([comment](https://github.com/pytorch/pytorch/pull/127235#issuecomment-2143518610))
- [Revert "Add noqa to prevent lint warnings (#127545)"](https://github.com/pytorch/pytorch/commit/d49dc8f4b8f57d14bc2e148e69f6168272c696a5)
  - reverting to unblock the revert of #127545 ([comment](https://github.com/pytorch/pytorch/pull/127545#issuecomment-2143517711))
- [Revert "Improve MAGMA conditional macro in BatchLinearAlgebra.cpp (#127495)"](https://github.com/pytorch/pytorch/commit/114c752b14e7f1226a889cf7939f32c20df06a38)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/127495#issuecomment-2143508218))
- [Revert "[BE] wrap deprecated function/class with `typing_extensions.deprecated` (#126898)"](https://github.com/pytorch/pytorch/commit/033e7330211e9c9f85cd7745c221aaccd02c5c76)
  - switching typing-extensions=4.3.0 to 4.9.0 causes internal failure ([comment](https://github.com/pytorch/pytorch/pull/126898#issuecomment-2142884456))
- [Revert "Add back private function torch.cuda.amp.autocast_mode._cast (#127433)"](https://github.com/pytorch/pytorch/commit/bbf892dd58dcd8a5683b56a365489ecc6fc67b0c)
  - depends on https://github.com/pytorch/pytorch/pull/126898 which is failing internally and needs to be reverted ([comment](https://github.com/pytorch/pytorch/pull/127433#issuecomment-2142869610))
- [Revert "[inductor][cpp] bf16/fp16 gemm template computed with fp32 w/o epilogue fusion (#126068)"](https://github.com/pytorch/pytorch/commit/029b3ec7754e13b260ec7931d98404d1023f0ed1)
  - failing internal tests ([comment](https://github.com/pytorch/pytorch/pull/126068#issuecomment-2141992307))
- [Revert "distributed debug handlers (#126601)"](https://github.com/pytorch/pytorch/commit/7646825c3eb687030c4f873b01312be0eed80174)
  - breaking internal typechecking tests ([comment](https://github.com/pytorch/pytorch/pull/126601#issuecomment-2141076987))
- [Revert "[Submodule] Remove deprecated USE_TBB option and TBB submodule (#127051)"](https://github.com/pytorch/pytorch/commit/67739d8c6ff0d6331b570a547346920bed810838)
  - This PR needs to be synced using the import button as there is a bug in our diff train ([comment](https://github.com/pytorch/pytorch/pull/127051#issuecomment-2138496995))
- [Revert "[Submodule] Remove deprecated USE_TBB option and TBB submodule (#127051)"](https://github.com/pytorch/pytorch/commit/cdbb2c9acc4d6ee93cbaa82896db43561a3b799b)
  - This PR needs to be synced using the import button as there is a bug in our diff train ([comment](https://github.com/pytorch/pytorch/pull/127051#issuecomment-2136428735))
- [Revert "Made some minor improvements to flexattention perf + added more autotune configs (#126811)"](https://github.com/pytorch/pytorch/commit/3f79e09515fba079ea09ca2544cbb1b5bfa9ed7c)
  - breaking on V100s / internal tests ([comment](https://github.com/pytorch/pytorch/pull/126811#issuecomment-2135798983))
- [Revert "Remove more of caffe2 (#126705)"](https://github.com/pytorch/pytorch/commit/00fe0a0d795680ade029fc552f33fffed75c0250)
  - Break internal build ([comment](https://github.com/pytorch/pytorch/pull/126705#issuecomment-2133325449))
- [Revert "[inductor][cpp] GEMM template (infra and fp32) (#124021)"](https://github.com/pytorch/pytorch/commit/4608971f7acd614c40822bfdeaa01882a99d01e7)
  - Break internal build ([comment](https://github.com/pytorch/pytorch/pull/124021#issuecomment-2133002071))
- [Revert "[inductor][cpp] epilogue support for gemm template (#126019)"](https://github.com/pytorch/pytorch/commit/343a41fba843f01359c93a169b11dca79033eefb)
  - Break internal build ([comment](https://github.com/pytorch/pytorch/pull/124021#issuecomment-2133002071))
- [Revert "[inductor][cpp] bf16/fp16 gemm template computed with fp32 w/o epilogue fusion (#126068)"](https://github.com/pytorch/pytorch/commit/68fddebf844a128913df2e5dba7adc0a8a5bc157)
  - Break internal build ([comment](https://github.com/pytorch/pytorch/pull/124021#issuecomment-2133002071))
- [Revert "[inductor][cpp] support bf16/fp16 gemm template epilogue fusion (#126545)"](https://github.com/pytorch/pytorch/commit/ed9951ace7cd6160aadbd74adaffe5f338199caa)
  - Break internal build ([comment](https://github.com/pytorch/pytorch/pull/124021#issuecomment-2133002071))
- [Revert "[Inductor][CPP] Add Min/Max with VecMask (#126841)"](https://github.com/pytorch/pytorch/commit/4c2e671a3b10e6d73fe764b677b0ee67f6cdc904)
  - Blocks reverting of the broken PR ([comment](https://github.com/pytorch/pytorch/pull/126841#issuecomment-2132995404))
- [Revert "[Inductor][CPP] Add ne with VecMask (#126940)"](https://github.com/pytorch/pytorch/commit/52474463964780fd5ed0454a7cdd525116e7d226)
  - Blocks reverting of the broken PR ([comment](https://github.com/pytorch/pytorch/pull/126841#issuecomment-2132995404))
- [Revert "Move MKLDNN Specific IR to Separate File (#126504)"](https://github.com/pytorch/pytorch/commit/60523fa674cc780d667ae1e5c8d89d5b83bd7965)
  - Blocks reverting of the broken PR ([comment](https://github.com/pytorch/pytorch/pull/126841#issuecomment-2132995404))

### Ignored Signal (2)

- [Revert "Reduce number of samples in {svd,pca}_lowrank OpInfos (#127199)"](https://github.com/pytorch/pytorch/commit/846f79e61ab2caab5cef0cc46e79f439ac9634ab)
  - Sorry for reverting your change but it is failing MacOS trunk job https://hud.pytorch.org/pytorch/pytorch/commit/18a3f781e6382e2222d7c30c18136267407f9953#25619618844 ([comment](https://github.com/pytorch/pytorch/pull/127199#issuecomment-2140834363))
- [Revert "[Caffe2]Remove Caffe2 proto files (#126134)"](https://github.com/pytorch/pytorch/commit/7a506dd0057ec82f17d72dcf308e2c5eaa4d80f7)
  - Broke bazel builds, see https://github.com/pytorch/pytorch/actions/runs/9278148147/job/25528691981 ([comment](https://github.com/pytorch/pytorch/pull/126134#issuecomment-2136373096))

### Landrace (2)

- [Revert "[DeviceMesh] Adding nD slicing support back (#127465)"](https://github.com/pytorch/pytorch/commit/f6e303fa47b6eb431db7a80a95f56574dfddc297)
  - Sorry for reverting your change but it is failing lint https://hud.pytorch.org/pytorch/pytorch/commit/e72232f8f032b970b74da18200678b3a4617bf95, the error does not like look trivial fix, so I revert the change for a forward fix ([comment](https://github.com/pytorch/pytorch/pull/127465#issuecomment-2141051630))
- [Revert "[5/N][Easy] fix typo for `usort` config in `pyproject.toml` (`kown` -> `known`): sort torch (#127126)"](https://github.com/pytorch/pytorch/commit/55c0ab2887bb6c94ead12dca70e419051442c11b)
  - Broken CI ([comment](https://github.com/pytorch/pytorch/pull/127126#issuecomment-2133044286))

### Not through pytorchbot (2)

- [Revert "Refresh OpOverloadPacket if a new OpOverload gets added (#126863)" (#127366)](https://github.com/pytorch/pytorch/commit/82a370ae3aacbbc1d8ec65deda0147999d055765)
- [Back out "Prevent partitioner from ever saving views (#126446)" (#127316)](https://github.com/pytorch/pytorch/commit/85172fbe84eb32521b6070c70ff83757bde0b74e)

### No Signal (8)

- [Revert "[ROCm] Update triton pin to fix libtanh issue (#125396)"](https://github.com/pytorch/pytorch/commit/58b461d57adef45949418e0f594dd4f2892f8ece)
  - Broke nightly builds ([comment](https://github.com/pytorch/pytorch/pull/125396#issuecomment-2142638237))
- [Revert "Enable UFMT on test_shape_ops.py test_show_pickle.py test_sort_and_select.py (#127165)"](https://github.com/pytorch/pytorch/commit/e02971fcfb3a972781c713cfa2f677d451f0306a)
  - lint is failing ([comment](https://github.com/pytorch/pytorch/pull/127165#issuecomment-2140930658))
- [Revert "[inductor] fix mkldnn linear binary fusion check ut (#127296)"](https://github.com/pytorch/pytorch/commit/12d6446507df794e5f1f563250bbbd8bbd08044b)
  - Sorry for reverting you change but one of the tests is failing on trunk ROCm.  Please help fix and reland the change https://github.com/pytorch/pytorch/actions/runs/9302535020/job/25606932572 ([comment](https://github.com/pytorch/pytorch/pull/127296#issuecomment-2140334323))
- [Revert "Add torchao nightly testing workflow (#126885)"](https://github.com/pytorch/pytorch/commit/ea5c17de9050db2fc97bd38d209c740631b85ab7)
  - Broke inductor periodic test ([comment](https://github.com/pytorch/pytorch/pull/126885#issuecomment-2140139486))
- [Revert "[compiled autograd] torch.compile API (#125880)"](https://github.com/pytorch/pytorch/commit/ce63b676f365b291e7cb966e3299a8121bf99b3c)
  - sorry your PR broke lint, need to revert ([comment](https://github.com/pytorch/pytorch/pull/125880#issuecomment-2139605376))
- [Revert "Enable Wunused-variable on tests (#127161)"](https://github.com/pytorch/pytorch/commit/52e448a7f9bd86ce1f49da72092eac33a8a00528)
  - Broke ReduceTests on Windows (by testing more), see https://github.com/pytorch/pytorch/actions/runs/9274944325/job/25519484937 ([comment](https://github.com/pytorch/pytorch/pull/127161#issuecomment-2136339435))
- [Revert "[FSDP2] Added test for N-way TP and 1-way FSDP with CPU offloading (#127024)"](https://github.com/pytorch/pytorch/commit/c7f6fbfa9d028bfba15d22b9e7a259724211ec39)
  - failing in CI ([comment](https://github.com/pytorch/pytorch/pull/127024#issuecomment-2133566325))
- [Revert "Add compile time profiler for non fbcode targets (#126904)"](https://github.com/pytorch/pytorch/commit/7121ea6f7094a65244bac47b57b6302f213a817f)
  - Broke nightly smoke test ([comment](https://github.com/pytorch/pytorch/pull/126904#issuecomment-2133418687))

### Weird (1)

- [Revert "[CI] add xpu test in periodic workflow (#126410)"](https://github.com/pytorch/pytorch/commit/e9a6bbbf7c60583fb2fba132c15122bb12c728ec)
  - Let's sync up on the test strategy/policies here ([comment](https://github.com/pytorch/pytorch/pull/126410#issuecomment-2140269549))
