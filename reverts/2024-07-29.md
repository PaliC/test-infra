# Week of 2024-07-29 to 2024-08-05 (44)

### GHFirst (11)

- [Revert "Add basic mypy annotations to dynamo (#132415)"](https://github.com/pytorch/pytorch/commit/3558a8cf4a97971f3feeee582ab352ae6c32e550)
  - Sorry, this PR has entered a weird state in the diff train. Trying to revert it to skip it, and then we can try relanding it ([comment](https://github.com/pytorch/pytorch/pull/132415#issuecomment-2267631785))
- [Revert "Add basic mypy annotations to inductor (#132416)"](https://github.com/pytorch/pytorch/commit/f2ddd5e9e0ee0e400031a834b9a12fe16691a4f2)
  - Sorry, this PR has entered a weird state in the diff train. Trying to revert it to skip it, and then we can try relanding it ([comment](https://github.com/pytorch/pytorch/pull/132415#issuecomment-2267631785))
- [Revert "[inductor] Add type hints to functions in mkldnn_fusion.py (#131820)"](https://github.com/pytorch/pytorch/commit/9be33bc5846d5127b5ed2bae34385d06f3355a00)
  - Sorry, had to revert this to revert another PR that depends on this change ([comment](https://github.com/pytorch/pytorch/pull/131820#issuecomment-2267629534))
- [Revert "[dynamo] revert map/zip iterator related changes (#132528)"](https://github.com/pytorch/pytorch/commit/0a25666f927373e24746c2c2dc587af29547d616)
  - This stack entered a weird state in the diff train. Reverting and relanding to clean the state ([comment](https://github.com/pytorch/pytorch/pull/132528#issuecomment-2267628475))
- [Revert "C++ network flow implementation in c10 (#132188)"](https://github.com/pytorch/pytorch/commit/00097f3458a849f1a633576fbaac5cadcef56f42)
  - Sorry but this appears to be failing internal tests. Please see D60702564 to investigate ([comment](https://github.com/pytorch/pytorch/pull/132188#issuecomment-2267098420))
- [Revert "Grouped Query Attention (#128898)"](https://github.com/pytorch/pytorch/commit/bcb4f7c1722def4fa17db1c9db9aeba038387382)
  - Sorry, this broke a bunch of tests internally. See D60638265 ([comment](https://github.com/pytorch/pytorch/pull/128898#issuecomment-2265961038))
- [Revert "[11/N] Use std::nullopt and std::optional (#132396)"](https://github.com/pytorch/pytorch/commit/e4e3575fb0ca549da5ca567cd928ad6c9e1c5660)
  - Sorry, but this PR has a dependency on another PR (https://github.com/pytorch/pytorch/pull/128898) that has to be reverted ([comment](https://github.com/pytorch/pytorch/pull/132396#issuecomment-2265952528))
- [Revert "Always use high precision for SDPA math backend (#128922)"](https://github.com/pytorch/pytorch/commit/59b73079a0437dd876339b2ef67e33f470c1aceb)
  - Sorry, but this PR has a dependency on another PR (https://github.com/pytorch/pytorch/pull/128898) that has to be reverted ([comment](https://github.com/pytorch/pytorch/pull/128922#issuecomment-2265949958))
- [Revert "Fix inlining module-scoped store global (#132224)"](https://github.com/pytorch/pytorch/commit/40c8f73099459849a614ed24d6071da027c6e9fd)
  - Looks like the new import mock_store_global_crossfile_inline fails internally. Please see D60567756 for details ([comment](https://github.com/pytorch/pytorch/pull/132224#issuecomment-2263768729))
- [Revert "[reland][inductor] switch AotCodeCompiler to new cpp_builder (#130127)"](https://github.com/pytorch/pytorch/commit/239d4d248908b3410ff40b5ceab02995a7d75f51)
  - broke internal tests ([comment](https://github.com/pytorch/pytorch/pull/130127#issuecomment-2258871791))
- [Revert "[pt2e][quant] Ensure BN node is erased after convert (#131651)"](https://github.com/pytorch/pytorch/commit/e73a4cb21fa031363848ab7bd852114bfb61eb11)
  - breaking internal builds ([comment](https://github.com/pytorch/pytorch/pull/131651#issuecomment-2256407968))

### Landrace (4)

- [Revert "[easy] fix f-string messages in torch/_ops.py (#132531)"](https://github.com/pytorch/pytorch/commit/21d02f8b4bd973c513e9d808f07d80587dca990e)
  - broke lint and tests due to conflict with 132377 ([comment](https://github.com/pytorch/pytorch/pull/132531#issuecomment-2266743391))
- [Revert "Ban decorator usage of dynamo_timed (#132328)"](https://github.com/pytorch/pytorch/commit/c8958f8f8429669738f8590d4301dc77cfbad42a)
  - Nope it was the one before this ~seems to have broken functorch/test_aotdispatch.py::TestAOTAutograd::test_input_data_and_metadata_mutation_aliases_other_input [GH job link](https://github.com/pytorch/pytorch/actions/runs/10204547165/job/28233976446) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/9853c048eb53946eb505424b17ac42ce46b66ac1).  Test passed on PR, probably a landrace, base is only 10 hours old~ ([comment](https://github.com/pytorch/pytorch/pull/132328#issuecomment-2263909337))
- [Revert "Migrate Inductor scheduler, dependencies, ir, and codegen/common to use OrderedSet (#130004)"](https://github.com/pytorch/pytorch/commit/784a6ec5a30bd2d1831cb4f78183ad51696794e5)
  - broke lint [GH job link](https://github.com/pytorch/pytorch/actions/runs/10183945999/job/28170099930) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/13d744464f10e35c0de50feb4e2340d4dae8e05f) probably a landrace, the base is 21 hours old ([comment](https://github.com/pytorch/pytorch/pull/130004#issuecomment-2260946562))
- [Revert "Let dynamo inline functional_call (#128646)"](https://github.com/pytorch/pytorch/commit/f72266eceaf833cd1a44d8e4ac611bc36102539c)
  - the newly added test dynamo/test_higher_order_ops.py::FuncTorchHigherOrderOpTests::test_functional_call_sequential_params_and_buffers [GH job link](https://github.com/pytorch/pytorch/actions/runs/10147452270/job/28058682000) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/5aab1acc84ff4a4374c9ddd179be48b07c6c8a74) is broken, probably a landrace since it passed on PR ([comment](https://github.com/pytorch/pytorch/pull/128646#issuecomment-2256375501))

### Not through pytorchbot (1)

- [Back out "[1/2] PT2 Inductor ComboKernels - Foreach cases (#124969)" (#132065)](https://github.com/pytorch/pytorch/commit/5298acb5c76855bc5a99ae10016efc86b27949bd)

### No Signal (21)

- [Revert "[easy] fix f-string messages in torch/_ops.py (#132531)"](https://github.com/pytorch/pytorch/commit/5dac4d2c780eb1ba4a2eab1e1e4e65c54993cc6c)
  - still breaks tests ([comment](https://github.com/pytorch/pytorch/pull/132531#issuecomment-2267584289))
- [Revert "[export] Convert autocast to HOO (#131914)"](https://github.com/pytorch/pytorch/commit/d9841057486db5db04a0e0aace2fa3c19b109389)
  - Failing lint, but was covered up by master failure on lint ([comment](https://github.com/pytorch/pytorch/pull/131914#issuecomment-2267248773))
- [Revert "[dynamo] Wrap unspecialized nn module getattr with UnspecializedNNModuleSource (#132308)"](https://github.com/pytorch/pytorch/commit/24d0a32f98035cef7fd998eb270fc40528ba0c61)
  - broke internal tests ([comment](https://github.com/pytorch/pytorch/pull/132308#issuecomment-2265959993))
- [Revert "[dynamo] Track builtin nn modules with UnspecializedBuiltinNNModuleVariable (#132314)"](https://github.com/pytorch/pytorch/commit/e696f17467bea791eba3c5d9720e52bb931ba152)
  - broke internal tests ([comment](https://github.com/pytorch/pytorch/pull/132314#issuecomment-2265953367))
- [Revert "[dynamo] Treat attr of unspecialized buiitin nn modules as static (#132318)"](https://github.com/pytorch/pytorch/commit/193a19ee918af185310b773f915ee8438f6126f0)
  - broke internal tests ([comment](https://github.com/pytorch/pytorch/pull/132318#issuecomment-2265945433))
- [Revert "[dynamo] Track params/buffers and mark them as static (#132334)"](https://github.com/pytorch/pytorch/commit/b8f7019df0950c8f0fb492173b3196ec852d5bda)
  - broke internal tests ([comment](https://github.com/pytorch/pytorch/pull/132334#issuecomment-2265942261))
- [Revert "Refactor thunkify to return proper thunk abstraction (#132407)"](https://github.com/pytorch/pytorch/commit/8fff976355dc0a41c585d67e2ecdfafc9caa4b7d)
  - test_correct_module_names ([comment](https://github.com/pytorch/pytorch/pull/132407#issuecomment-2265754857))
- [Revert "Don't attempt to compute hints for unbacked expressions (#132060)"](https://github.com/pytorch/pytorch/commit/1197550876d9e82f3fade9c4e9861dbd47ded22e)
  - test_correct_module_names ([comment](https://github.com/pytorch/pytorch/pull/132407#issuecomment-2265754857))
- [Revert "Change signature of CompilerFn for register_backend decorator (#131880)"](https://github.com/pytorch/pytorch/commit/d224857b3af5c9d5a3c7a48401475c09d90db296)
  - Breaking lint ([comment](https://github.com/pytorch/pytorch/pull/131880#issuecomment-2265682757))
- [Revert "[AOTI] Fix bfloat16 in CPU (#132150)"](https://github.com/pytorch/pytorch/commit/10344d76bd4145dcb87e5cdc5d93726a2e0fa15c)
  - I think this broke inductor/test_cuda_cpp_wrapper.py::DynamicShapesCudaWrapperCudaTests::test_unspec_inputs_cuda_dynamic_shapes_cuda_wrapper [GH job link](https://github.com/pytorch/pytorch/actions/runs/10189155341/job/28189531216) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/a488113062b7231197ace8522ab3cab535c77d0b). Test was not run on PR due to being skipped for being slow ([comment](https://github.com/pytorch/pytorch/pull/132150#issuecomment-2261895048))
- [Revert "AutoHeuristic: mixed_mm heuristic for A100 (#131613)"](https://github.com/pytorch/pytorch/commit/a28cda11ef69cfd515a3fb6086ce2a381e5ec808)
  - lintrunner issues ([comment](https://github.com/pytorch/pytorch/pull/131613#issuecomment-2261884149))
- [Revert "Add fx graph runnable to tl parse (#130976)"](https://github.com/pytorch/pytorch/commit/5406e46b00d4e7dc117070efd8ff0dc783f75dc2)
  - Broke trunk ([comment](https://github.com/pytorch/pytorch/pull/130976#issuecomment-2260579485))
- [Revert "Add functions from `torch.masked._ops` to `__all__` for `torch.masked` (#131288)"](https://github.com/pytorch/pytorch/commit/91299c95ece5b51902abf2dad9cb11ca550c72fe)
  - Broke test_public_bindings.py::TestPublicBindings::test_correct_module_names [GH job link](https://github.com/pytorch/pytorch/actions/runs/10172945925/job/28136657243) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/78020ea55d1bc06898577887b80c15d6d2b967dc) ([comment](https://github.com/pytorch/pytorch/pull/131288#issuecomment-2259581854))
- [Revert "BE: reset dynamo before each test in test_module.py (#131372)"](https://github.com/pytorch/pytorch/commit/d5e9fbb01239281c4f590a70316882c4b8832ef1)
  - Broke test_modules.py::TestModuleCUDA::test_cpu_gpu_parity_nn_CTCLoss_cuda_float32 [GH job link](https://github.com/pytorch/pytorch/actions/runs/10149118852/job/28065175173) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/ca8153ae6758fbf33cc767cfd0cb384b87b8d3ca) ([comment](https://github.com/pytorch/pytorch/pull/131372#issuecomment-2257019116))
- [Revert "BE: reset dynamo before each test in test_ops_gradients.py (#131397)"](https://github.com/pytorch/pytorch/commit/a4723b566fe3ab6088663206e2604cccf913c706)
  - Broke test_modules.py::TestModuleCUDA::test_cpu_gpu_parity_nn_CTCLoss_cuda_float32 [GH job link](https://github.com/pytorch/pytorch/actions/runs/10149118852/job/28065175173) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/ca8153ae6758fbf33cc767cfd0cb384b87b8d3ca) ([comment](https://github.com/pytorch/pytorch/pull/131372#issuecomment-2257019116))
- [Revert "Enable FlashAttention on Windows (#131906)"](https://github.com/pytorch/pytorch/commit/6cf493158ef1f427e04f43d5b0ba1d702718af09)
  - Windows nightly failures ([comment](https://github.com/pytorch/pytorch/pull/131906#issuecomment-2256421183))
- [Revert "[inductor] Fix unsoundness with negative-valued indexing expressions (#131761)"](https://github.com/pytorch/pytorch/commit/957a89f56cc0d9c6d6436ea7d49d657c321eda06)
  - Broke CI: inductor/test_cpu_cpp_wrapper.py::DynamicShapesCppWrapperCpuTests::test_linear_binary_dynamic_shapes_cpp_wrapper [GH job link](https://github.com/pytorch/pytorch/actions/runs/10145214748/job/28051168920) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/03760be2714c6ed3b4f44c4dc3ea016f557d8597) ([comment](https://github.com/pytorch/pytorch/pull/131761#issuecomment-2256287736))
- [Revert "[BE][tests] show local variables on failure in tests (#131151)"](https://github.com/pytorch/pytorch/commit/c35f21e5fcb8d7c65767b2e5a108cdd06c051596)
  - Broke CI: test_testing.py::TestTestingCUDA::test_cuda_assert_should_stop_common_device_type_test_suite_cuda [GH job link](https://github.com/pytorch/pytorch/actions/runs/10131415299/job/28014665693) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/14158d892a2bd9b34edb5637f9a05217ea0330bd) ([comment](https://github.com/pytorch/pytorch/pull/131151#issuecomment-2255921015))
- [Revert "[CI] add new test config label `ci-test-showlocals` to control test log verbosity (#131981)"](https://github.com/pytorch/pytorch/commit/06fe99a097abb355f8e8cb06d7b402ac998ad03f)
  - Sorry, need to revert bottom PR, which broke CI: https://github.com/pytorch/pytorch/pull/131151 - Failure: test_testing.py::TestTestingCUDA::test_cuda_assert_should_stop_common_device_type_test_suite_cuda [GH job link](https://github.com/pytorch/pytorch/actions/runs/10131415299/job/28014665693) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/14158d892a2bd9b34edb5637f9a05217ea0330bd) ([comment](https://github.com/pytorch/pytorch/pull/131981#issuecomment-2255892628))
- [Revert "[dynamo] Turn on inline_inbuilt_nn_modules (#131275)"](https://github.com/pytorch/pytorch/commit/7ef927da15537c2aeb81c8890078939c7cf0ed65)
  - Broke CI: dynamo/test_structured_trace.py::StructuredTraceTest::test_ddp_graphs [GH job link](https://github.com/pytorch/pytorch/actions/runs/10132084288/job/28016215101) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/6de65d5dd4226b6bae15352b575c81a6750c819b) ([comment](https://github.com/pytorch/pytorch/pull/131275#issuecomment-2255839646))
- [Revert "support zb1p and zb2p algorithms (#130752)"](https://github.com/pytorch/pytorch/commit/eb9409511e1c6ae0c5bf37121f500d91a34d6102)
  - Broke Periodic CI: distributed/pipelining/test_composability.py::ComposabilityTest::test_manual_with_data_parallel_dp_type_DDP_ScheduleClass4 [GH job link](https://github.com/pytorch/pytorch/actions/runs/10131472868/job/28014900187) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/8fe5b93667b60e37c12d288659a25cbd5ae53c79) ([comment](https://github.com/pytorch/pytorch/pull/130752#issuecomment-2255819078))

### Weird (7)

- [Revert "Ensure compiler collective is called even when no graph is compiled (#132163)"](https://github.com/pytorch/pytorch/commit/9eeb5eebaba874bea63935554eaa8d4324e6de91)
  - Incorrectly reverted ~test_correct_module_names~ ([comment](https://github.com/pytorch/pytorch/pull/132163#issuecomment-2265729449))
- [Revert "[export] Add print_readable to unflattener (#128617)"](https://github.com/pytorch/pytorch/commit/3855ac5a5d53fd4d2d6521744eaf80c2a95a4d54)
  - never got landed internally due to weird flow... sorry ([comment](https://github.com/pytorch/pytorch/pull/128617#issuecomment-2264224466))
- [Revert "[pytorch][counters] Pybind for WaitCounter (#132167)"](https://github.com/pytorch/pytorch/commit/dc38646c588906e840793936f32a197c7a837ba1)
  - broke test_public_bindings.py::TestPublicBindings::test_correct_module_names [GH job link](https://github.com/pytorch/pytorch/actions/runs/10183687967/job/28172929836) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/2c7bd61afa4b762e00b26bbde43685de080af32a) not tested on PR due to bad TD ([comment](https://github.com/pytorch/pytorch/pull/132167#issuecomment-2261328275))
- [Revert "Grouped Query Attention (#128898)"](https://github.com/pytorch/pytorch/commit/499ead96ffeab66dd7b394b0986be49ed1a91172)
  - Broken test on main, test not run due to bad TD ([comment](https://github.com/pytorch/pytorch/pull/128898#issuecomment-2258314481))
- [Revert "[NestedTensor] Integrate the softmax operator along the jagged dimension into NestedTensor (#131518)"](https://github.com/pytorch/pytorch/commit/7a7dd8c29e391a4054bc85f063ec0510975e1c42)
  - Sorry, reverting this since this is based on an internal diff that has diverged from actual internal commit (the final PR and diff must always be identical). Conflicts arise when that happens which block the diff train. Let's revert both this PR and the internal diff, and then reland them as a proper new codev diff ([comment](https://github.com/pytorch/pytorch/pull/131518#issuecomment-2257259839))
- [Revert "[NestedTensor] Integrate the layer normalization operator along the jagged dimension into NestedTensor (#131519)"](https://github.com/pytorch/pytorch/commit/be5e44192dfbcde9f75fa982e8de853f758d1140)
  - Sorry, reverting this since this is based on an internal diff that has diverged from actual internal commit.  Weird conflicts arise when that happens.  Let's revert both this PR and the internal diff, and then reland them as a proper new codev diff ([comment](https://github.com/pytorch/pytorch/pull/131519#issuecomment-2257230717))
- [Revert "Add config option to skip autotuning conv (#131839)"](https://github.com/pytorch/pytorch/commit/62b2e7a5530b25f4779c3fd948807d2fe9d2f97f)
  - wrong config name ([comment](https://github.com/pytorch/pytorch/pull/131839#issuecomment-2257117221))
