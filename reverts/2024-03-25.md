# Week of 2024-03-25 to 2024-04-01 (21)

### GHFirst (11)

- [Revert "Enable x86 CPU vectorization on windows [submodule sleef] (#118980)"](https://github.com/pytorch/pytorch/commit/5e878be101298acfb8ba1fdf8c1aee63d5e06143)
  - Breaks internal build ([comment](https://github.com/pytorch/pytorch/pull/118980#issuecomment-2028084839))
- [Revert "`_foreach_copy` with different src/dst dtypes (#121717)"](https://github.com/pytorch/pytorch/commit/958dbb876ce04002e6690db269f08df963d919f7)
  - Causing IMAs on V100s internally :C ([comment](https://github.com/pytorch/pytorch/pull/121717#issuecomment-2025553295))
- [Revert "Add RMSNorm module (#121364)"](https://github.com/pytorch/pytorch/commit/8698121636f24aec7fd354f1d3a7f12360497e4f)
  - Broke internal tests ([comment](https://github.com/pytorch/pytorch/pull/121364#issuecomment-2025502007))
- [Revert "[fx] Preserve Fx graph node order in partitioner across runs (#115621)"](https://github.com/pytorch/pytorch/commit/8007d9a34af8148165820135cbcfd8bad259cc05)
  - Broke internal executorch test ([comment](https://github.com/pytorch/pytorch/pull/115621#issuecomment-2025496296))
- [Revert "Optimize multi_tensor_apply (take 2) (#119764)"](https://github.com/pytorch/pytorch/commit/bef01c7c2b3ca8adf2bc40f4e8790a27457f3112)
  - Failing internally ([comment](https://github.com/pytorch/pytorch/pull/119764#issuecomment-2024105399))
- [Revert "[Inductor] Run pattern matcher over the original graph (#122519)"](https://github.com/pytorch/pytorch/commit/b63f6f78dc8a4e6f059b9abc4eb1eed1d490bcfc)
  - Breaks internal tests ([comment](https://github.com/pytorch/pytorch/pull/122519#issuecomment-2023022311))
- [Revert "Only update momentum buffers for SGD if momentum is enabled (#122349)"](https://github.com/pytorch/pytorch/commit/f140309e9cc155675c741cbe3962b9ddb7d0117c)
  - Broke internal tests ([comment](https://github.com/pytorch/pytorch/pull/122349#issuecomment-2023001467))
- [Revert "[xla hash update] update the pinned xla hash (#122628)"](https://github.com/pytorch/pytorch/commit/70c3deef2d8f356cce8e8531238fbee201fe8189)
  - Need revert and then reland ([comment](https://github.com/pytorch/pytorch/pull/122628#issuecomment-2022995857))
- [Revert "[dynamo] Forward OptimizedModule.__setattr__ to the wrapped module (#122098)"](https://github.com/pytorch/pytorch/commit/f6315860846709cb19f8c6f58534be828086627a)
  - Failing internally ([comment](https://github.com/pytorch/pytorch/pull/122098#issuecomment-2021233604))
- [Revert "[AOTInductor] Add tensor_constantX to pass constant buffer update's check (#122562)"](https://github.com/pytorch/pytorch/commit/55f36d1ada09917195892443295baf1cd0e5cfdd)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/122562#issuecomment-2019262415))
- [Revert "Change ATEN generator argument type to const std::optional<Generator>& (#120076)"](https://github.com/pytorch/pytorch/commit/db506762d12006e4df2e19477fad20f08fae9d15)
  - breaking internal builds ([comment](https://github.com/pytorch/pytorch/pull/120076#issuecomment-2018680656))

### Ignored Signal (1)

- [Revert "Support map in pre-dispatch functionalization (#121444)"](https://github.com/pytorch/pytorch/commit/6b8205d3ded6f2833b12411376527766a8318dfa)
  - sorry windows failure seems related https://hud.pytorch.org/pytorch/pytorch/commit/079feea3379c021a330dbfac7668a5fc8fccc3bd https://github.com/pytorch/pytorch/actions/runs/8474191301/job/23220791555. PR got force merged before windows job finished ([comment](https://github.com/pytorch/pytorch/pull/121444#issuecomment-2026323614))

### Not through pytorchbot (2)

- [Back out "Added a check in register_lowering to avoid decomposed ops (#117632)" (#122709)](https://github.com/pytorch/pytorch/commit/8a33a77fd1717e23286903927ca5663df91f616d)
- [Revert "[c10d] disable compute_duration by default (#122138)" (#122539)](https://github.com/pytorch/pytorch/commit/530e13cf3de4c089996c7d606c1bb526c16cd649)

### No Signal (5)

- [Revert "[aoti] clear precomputed symbol replacements before cpp wrapper compilation (#122882)"](https://github.com/pytorch/pytorch/commit/a236fa9f061097107520fcc4fdca5f731b16a04a)
  - broke ROCm CI ([comment](https://github.com/pytorch/pytorch/pull/122882#issuecomment-2027544640))
- [Revert "Add non strict inline constraints and runtime assertions to non-strict exported program (#122722)"](https://github.com/pytorch/pytorch/commit/3beb9d85a6501d8df5a89e2cc2d7cb0f8f94dbfc)
  - This breaks torchrec.distributed.tests.test_pt2.TestPt2: test_kjt__getitem__ ([comment](https://github.com/pytorch/pytorch/pull/122722#issuecomment-2026078351))
- [Revert "Workaround dind-rootless volumes mount as root (#122787)"](https://github.com/pytorch/pytorch/commit/8df99732a4e1767ddc7e32ede04cc9a18a00e6b6)
  - This broke rocm tests ([comment](https://github.com/pytorch/pytorch/pull/122787#issuecomment-2026022659))
- [Revert "[NJT] .to() properly updates device of offsets (#122797)"](https://github.com/pytorch/pytorch/commit/4290a57e9ce0af8b76268825bea32d9c9f4c852a)
  - Sorry for reverting your change but it is failing CUDA and ROCm jobs in trunk. Please help take a look and reland the change ([comment](https://github.com/pytorch/pytorch/pull/122797#issuecomment-2025473181))
- [Revert "Graph-Safe RNG State Exchange for Tensor Parallelism (#114068)"](https://github.com/pytorch/pytorch/commit/4dc09d6aa4d1a04a10df5088783532f131f59cfe)
  - memory leak in another ci ([comment](https://github.com/pytorch/pytorch/pull/114068#issuecomment-2018044527))

### Weird (2)

- [Revert "Let dynamo trace some functions in functorch.deprecated.* namespace (#121665)"](https://github.com/pytorch/pytorch/commit/6e1c81c68771757f59a39bb1ca7841ddc758d124)
  - revert PR ([comment](https://github.com/pytorch/pytorch/pull/121665#issuecomment-2025460500))
- [Revert "[TorchGen] Add mutable parameter to valuetype_type function in api/cpp.py (#121415)"](https://github.com/pytorch/pytorch/commit/b2c496ba24f8e9dd9a8ce9a7447e33ad63616db3)
  - I think this needs to be reverted to after https://github.com/pytorch/pytorch/pull/120076 revert ([comment](https://github.com/pytorch/pytorch/pull/121415#issuecomment-2018828813))
