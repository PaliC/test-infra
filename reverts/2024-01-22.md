# Week of 2024-01-22 to 2024-01-29 (16)

### GHFirst (6)

- [Revert "[Exception] [6/N] Remove use of torch::TypeError (#117964)"](https://github.com/pytorch/pytorch/commit/dabb90f2a4e07e3f7062cff801a55bc408349f4b)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/117964#issuecomment-1913079096))
- [Revert "Use SEQUENTIAL posix_fadvise on mmapped files (#117805)"](https://github.com/pytorch/pytorch/commit/af8f37c2b6f9f670ee8154e81ebd9fce7843f60e)
  - Break internal build ([comment](https://github.com/pytorch/pytorch/pull/117805#issuecomment-1912204403))
- [Revert "[dtensor] rewrite embedding ops using op strategy (#118079)"](https://github.com/pytorch/pytorch/commit/fc30bd3b7b040a95fc9c077b157542f8e97dc73c)
  - Break internal build ([comment](https://github.com/pytorch/pytorch/pull/118079#issuecomment-1911681293))
- [Revert "[dtensor] implement dim-0 (row) embedding sharding with MaskPartial (#118080)"](https://github.com/pytorch/pytorch/commit/bfb5e7642e8fe2d6c3743f5a76ad0d290e94ab9c)
  - Break internal build ([comment](https://github.com/pytorch/pytorch/pull/118079#issuecomment-1911681293))
- [Revert "[tp] enable rowwise embedding sharding in RowwiseParallel (#118242)"](https://github.com/pytorch/pytorch/commit/bc67f87559f1e840c67bc3e1bcba48ad107aa441)
  - Break internal build ([comment](https://github.com/pytorch/pytorch/pull/118079#issuecomment-1911681293))
- [Revert "accelerate `binary_cross_entropy_with_logits` by using `log_sigmoid` operator (#115539)"](https://github.com/pytorch/pytorch/commit/8dc421a6b480eaa39971c8f16919f7f4dc094852)
  - Break internal build ([comment](https://github.com/pytorch/pytorch/pull/115539#issuecomment-1904157729))

### Not through pytorchbot (2)

- [Revert "[Dynamo, ONNX] use environment variable ONNXRT_DUMP_PATH to dump onnx models created by onnxrt backend (#117551)"](https://github.com/pytorch/pytorch/commit/13bdd6c4e2ae1e4224a378decc5a762402dacbba)
- [Revert "Update triton ROCm version to 6.0" (#118179)](https://github.com/pytorch/pytorch/commit/e6288820e3a2ae385a0ad51b412c43f384827787)

### No Signal (2)

- [Revert "Check if enable inside run call (#118101)"](https://github.com/pytorch/pytorch/commit/533637d9a37845c86b24f670201c8d0d6f690a9b)
  - broke periodic multigpu test some how https://hud.pytorch.org/pytorch/pytorch/commit/6fc015fedc96e532da756e9408fcedb9c81a423f ([comment](https://github.com/pytorch/pytorch/pull/118101#issuecomment-1912357321))
- [Revert "[c10d] Barrier uses stream sync instead of device sync (#117804)"](https://github.com/pytorch/pytorch/commit/b5799d99773963b41c0a45ad001db8e52335931e)
  - sorry the docs test failure is real, I think it wants the lines after the .. note to be indented https://hud.pytorch.org/pytorch/pytorch/commit/0f6bbb1c070c3a9713893659377e20e147c125f6 https://github.com/pytorch/pytorch/actions/runs/7616827874/job/20745016788.  There are also some libtorch builds failing.  This looks to be some combination of ignoredsignal (docs build) and nosignal (Dr CI classification for docs_test was wrong, pending libtorch jobs) ([comment](https://github.com/pytorch/pytorch/pull/117804#issuecomment-1904882487))

### Weird (6)

- [Revert "[pytorch][kineto] log process group config in distributed info (#117774)"](https://github.com/pytorch/pytorch/commit/3d062f9abe9db13119b31bf810cc4834dc2d9a26)
  - This diff is breaking internal jobs, but has been internally reverted ([comment](https://github.com/pytorch/pytorch/pull/117774#issuecomment-1911251092))
- [Revert "Fix Auto Functionalize to handle specified default values (#118035)"](https://github.com/pytorch/pytorch/commit/eb054cc0123fe7c19e624b885c6230ce3f02c2e5)
  - needs internal changes, reverting so we can land via co-dev ([comment](https://github.com/pytorch/pytorch/pull/118035#issuecomment-1910706841))
- [Revert "Check if enable inside run call (#118101)"](https://github.com/pytorch/pytorch/commit/af9b6fa04e7460b64e634b1aecd0ef32cd0d1ddc)
  - possibly causing failures on b025e5984ce30eed10df0cc89111e88983d823d3 ([comment](https://github.com/pytorch/pytorch/pull/118101#issuecomment-1908940940))
- [Revert "Log stack trace of mutated idx (#117720)"](https://github.com/pytorch/pytorch/commit/58e7ec5843e63ee044e0a4f5aa2583a056a64078)
  - cause of https://github.com/pytorch/pytorch/issues/118104 ([comment](https://github.com/pytorch/pytorch/pull/117720#issuecomment-1906693119))
- [Revert "[ez] Provide a slightly better error message if process times out (#117865)"](https://github.com/pytorch/pytorch/commit/5ec2d7959d1ef1e8eeacc5e59bbf0f8b2dda1ea6)
  - Does not play nice with retry_shell, which expects timeoutexpired, but i cant control the error message of that ([comment](https://github.com/pytorch/pytorch/pull/117865#issuecomment-1906640922))
- [Revert "Remove skips for passing tests (#118000)"](https://github.com/pytorch/pytorch/commit/bb28965924cd142a9d12f475fa646c45acb8639f)
  - test passing on diff but failing on hud... ([comment](https://github.com/pytorch/pytorch/pull/118000#issuecomment-1905351752))
