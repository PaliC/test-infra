# Week of 2023-09-04 to 2023-09-11 (30)

### GHFirst (12)

- [Revert "[Dynamo][Test]Add a testcase for module with training state (#108750)"](https://github.com/pytorch/pytorch/commit/92de1d2d028720530e26daaa93f27e2bf3cee4da)
  - Sorry for reverting you change, but it starts failing this test https://github.com/pytorch/pytorch/issues/108838 without https://github.com/pytorch/pytorch/pull/108883 and the latter has been reverted ([comment](https://github.com/pytorch/pytorch/pull/108750#issuecomment-1712708800))
- [Revert "reland [finishing colesbury's PR 100642] Guard on nn.Module dicts and type (#108883)"](https://github.com/pytorch/pytorch/commit/56c23861573e4dfb2252fc6c29bfc74979816b9f)
  - Per the discussion thread on D49122208, reverting this change ([comment](https://github.com/pytorch/pytorch/pull/108883#issuecomment-1712707853))
- [Revert "Re-land: Break graph on `manual_seed`. (#108647)"](https://github.com/pytorch/pytorch/commit/8caaa4f4cdac6657f72c48607b6a732a975c5d20)
  - Ouch, we are hit again my another internal import error from https://github.com/pytorch/pytorch/blob/main/torch/_inductor/config.py#L205-L206 ([comment](https://github.com/pytorch/pytorch/pull/108647#issuecomment-1712230103))
- [Revert "Reland: Add PyObject preservation for UntypedStorage (#103907)"](https://github.com/pytorch/pytorch/commit/68238606f3e9f70ac000187ed17ea347fdc0c549)
  - Sorry for reverting your change, but it is failing torchdistx build which uses check_pyobj here https://github.com/pytorch/torchdistx/blob/9c1b9f5cb2fa36bfb8b70ec07c40ed42a33cc87a/src/python/torchdistx/_C/deferred_init.cc#L87 ([comment](https://github.com/pytorch/pytorch/pull/103907#issuecomment-1712121158))
- [Revert "[inductor] Switch to use the runtime interface for AOTInductor testing (#108663)"](https://github.com/pytorch/pytorch/commit/428f5f9e7eb98b1c3a82f8ee22da5a8853b2dea5)
  - Sorry :'( Need to revert to resolve merge conflict for another revert ([comment](https://github.com/pytorch/pytorch/pull/108663#issuecomment-1711076411))
- [Revert "[export] Fix dict.get() to dict.setdefault() for param lookup. (#108587)"](https://github.com/pytorch/pytorch/commit/1aacbaed8b7b85afe93d039fd27e2b1d2f77bb8f)
  - Sorry for reverting your change, but it is failing one internal test.  Please take a look at the diff D48995555 for more details ([comment](https://github.com/pytorch/pytorch/pull/108587#issuecomment-1708933010))
- [Revert "Use global variables to register the return_types namedtuples (#107000)"](https://github.com/pytorch/pytorch/commit/27d5dcf5894ada88adaece58e34915416856443f)
  - Sorry for reverting your change, but it is failing internal build ([comment](https://github.com/pytorch/pytorch/pull/107000#issuecomment-1708862325))
- [Revert "Use std::filesystem in c10 tempfile and tempdir (#106656)"](https://github.com/pytorch/pytorch/commit/1b76a5c24b1de811770686b5a2538f4290e2e628)
  - Sorry for reverting your change, but it is failing internal iOS build.  This was missed by period mobile build I think ([comment](https://github.com/pytorch/pytorch/pull/106656#issuecomment-1707187814))
- [Revert "Eliminate c10::guts::to_string (#108480)"](https://github.com/pytorch/pytorch/commit/8da04e023e0dab439712e1099dd65edac5e88de6)
  - Sorry for reverting this, but this is needed to keep trunk green after https://github.com/pytorch/pytorch/pull/108479 was reverted.  Both will need to be relanded ([comment](https://github.com/pytorch/pytorch/pull/108480#issuecomment-1707067595))
- [Revert "[NCCL][CUDA][CUDA Graphs] Flush enqueued work before starting a graph capture (#104487)"](https://github.com/pytorch/pytorch/commit/5b31a418412c11c4e7990fb6f9f9eebb40fe632c)
  - Sorry for reverting you change, it is failing internal build ([comment](https://github.com/pytorch/pytorch/pull/104487#issuecomment-1707055346))
- [Revert "Simplify c10::string_view implementation (#108479)"](https://github.com/pytorch/pytorch/commit/9f71a4ebd462b95e1b45df4a89f00ac83b9d77ac)
  - Sorry for reverting you change, it is failing internal builds ([comment](https://github.com/pytorch/pytorch/pull/108479#issuecomment-1707033082))
- [Revert "Break graph on `manual_seed`. (#107594)"](https://github.com/pytorch/pytorch/commit/48286d34a417e14bce6b79e2795badd5e134f214)
  - Sorry for reverting your change, but it has an import issue that breaks internal code ([comment](https://github.com/pytorch/pytorch/pull/107594#issuecomment-1705584405))

### Ignored Signal (2)

- [Revert "Revert "Flash Attention v2 (#105602)" (#108827)"](https://github.com/pytorch/pytorch/commit/e45b29012786a88e02e1a9bf2a64622e5ca55be3)
  - I need to land this revert properly as there are new failures showing up on trunk ([comment](https://github.com/pytorch/pytorch/pull/108827#issuecomment-1711020924))
- [Revert "[dynamo] Add BACKEND_MATCH guard to detect and recompile when backend changes (#107337)"](https://github.com/pytorch/pytorch/commit/38fcf77a1bd6fd8a18a74a17ed02c19730169e6c)
  - Sorry for reverting your change but inductor perf smoke test starts to regress after this ([comment](https://github.com/pytorch/pytorch/pull/107337#issuecomment-1710974588))

### Not through pytorchbot (9)

- [Revert "[export] Lift constant tensors as buffers (#108592)" (#108893)](https://github.com/pytorch/pytorch/commit/703cdd711f6293990c243017b5db2e06972721cd)
- [Back out "[Dynamo x FSDP] Add support for params, buffers, submodules on FSDPManagedNNModuleVariable (#107923)" (#108823)](https://github.com/pytorch/pytorch/commit/366baf690b1dafcd1c27692ea84f32f62d6c9291)
- [Back out "[PyPer][BE] Fix test_scripted_module in StatCollector" (#108588)](https://github.com/pytorch/pytorch/commit/51c2b587c95d5471352379c24504bfb98d381781)
- [Revert "Flash Attention v2 (#105602)" (#108827)](https://github.com/pytorch/pytorch/commit/a9c663c269f133b37e257014b93112f6af8a10c1)
- [Back out "Horizontally fuse input concatenation (#108115)" (#108793)](https://github.com/pytorch/pytorch/commit/6c7260407b35aadcaf7807cbc2ad320a16ced785)
- [Revert "Flash Attention v2 (#105602)" (#108827)](https://github.com/pytorch/pytorch/commit/24e9bbe22af296048f8242c6112d13cff726c588)
- [Revert "Force synced KJT to trace unbacked SymInt (#107788)" (#108684)](https://github.com/pytorch/pytorch/commit/5a4fe05a15d84cf3a2b8c69a6ec8160f0bb95f0e)
- [Back out "Faster gc_count update for CUDACachingAllocator" (#108632)](https://github.com/pytorch/pytorch/commit/aebb86fef735a2252176526c50df35054e52124a)
- [Revert "[export] Copy gm before calling PassManager" for test or build failures (#108441)](https://github.com/pytorch/pytorch/commit/a9a6423261096877da9931d81d09ab1d85d8275c)

### No Signal (4)

- [Revert "increase clang-tidy coverage in torch/csrc (#103058)"](https://github.com/pytorch/pytorch/commit/fa8bfe5ca28c44361519cbb507dca1302d70291d)
  - Sorry for reverting your change, breaks lint ([comment](https://github.com/pytorch/pytorch/pull/103058#issuecomment-1711906915))
- [Revert "[inductor] Add ir.Scan and lower aten.cumsum on CUDA (#106581)"](https://github.com/pytorch/pytorch/commit/8ba23e48fa8f608a8ac6382973f9b50308658d2c)
  - Sorry for reverting your change, but it broke rocm CI ([comment](https://github.com/pytorch/pytorch/pull/106581#issuecomment-1710776610))
- [Revert "[dynamo][activation checkpointing] Trace through ActivationWrapper (#108599)"](https://github.com/pytorch/pytorch/commit/77691e8bc3d5e923f9fc0d9748677971c2f04cff)
  - Sorry for reverting your change, but test_ddp_activation_checkpointing is failing distributed ROCm test in trunk ([comment](https://github.com/pytorch/pytorch/pull/108599#issuecomment-1710479387))
- [Revert "Remove fixed skips (#108674)"](https://github.com/pytorch/pytorch/commit/43527d41a255322003fd806eaefce56f0de7bfb0)
  - Sorry for reverting this, but one test is failing on inductor https://hud.pytorch.org/pytorch/pytorch/commit/518cfda2dd0e940603c74717b4cb33493a9ec908, and it seems easier to revert this than disabling the test ([comment](https://github.com/pytorch/pytorch/pull/108674#issuecomment-1709310192))

### Weird (3)

- [Revert "[dynamo][finishing colesbury's PR 100642] Guard on nn.Module dicts and type (#108528)"](https://github.com/pytorch/pytorch/commit/72f24d000195952aa3130e84c7267390405a5ed6)
  - Sorry for reverting your change, but it has some nasty merge conflicts after the revert of D48910794. I need to revert this so the conflict could be resolved and unblock diff train. Please help rebase this tomorrow and reland the change ([comment](https://github.com/pytorch/pytorch/pull/108528#issuecomment-1711034781))
- [Revert "Skip ROCm jobs on PR (for now) (#108083)"](https://github.com/pytorch/pytorch/commit/6a304ed1f271cd249b4277d1fa5b1d219d0a1609)
  - ROCm queue looks better now, reverting this to see if the queue looks ok before picking up https://github.com/pytorch/test-infra/issues/4516 ([comment](https://github.com/pytorch/pytorch/pull/108083#issuecomment-1709222748))
- [Revert "docs: Match open bracket with close bracket in unsqueeze (#95215)"](https://github.com/pytorch/pytorch/commit/e5e653a660089e4d951a21921468f453ea9ed141)
  - Incorrect assumptions ([comment](https://github.com/pytorch/pytorch/pull/95215#issuecomment-1708852420))
