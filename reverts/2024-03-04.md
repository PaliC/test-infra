# Week of 2024-03-04 to 2024-03-11 (19)

### GHFirst (9)

- [Revert "Change ATEN generator argument type to const std::optional<Generator>& (#120076)"](https://github.com/pytorch/pytorch/commit/c0996866f4709fedf72170de924e76c115c1a578)
  - breaking internal builds(take 3) ([comment](https://github.com/pytorch/pytorch/pull/120076#issuecomment-1986338164))
- [Revert "[fx] Preserve Fx graph node order in partitioner across runs (#115621)"](https://github.com/pytorch/pytorch/commit/27a09009468affa114f87a52cdf23ddf403ebe4d)
  - depends on #120076, which needs to be reverted ([comment](https://github.com/pytorch/pytorch/pull/115621#issuecomment-1986324796))
- [Revert "Update XLA pin (#121501)"](https://github.com/pytorch/pytorch/commit/bc117898f18e8a698b00823f57c19b2d874b93ba)
  - We are trying to revert underlying change first ([comment](https://github.com/pytorch/pytorch/pull/121501#issuecomment-1986289409))
- [Revert "[compiled autograd] support custom ops backed by c++ autograd::Function (#120681)"](https://github.com/pytorch/pytorch/commit/2b1661c7a023bfe8ea9b46c73a585f1bfd174208)
  - breaking internal builds, see D54617701 ([comment](https://github.com/pytorch/pytorch/pull/120681#issuecomment-1984214079))
- [Revert "[ATen][CUDA][CUBLAS] cublasLtMatmul increase workspace_size (#120925)"](https://github.com/pytorch/pytorch/commit/862b99b571e7544c82232aa6956a8ddd0ab247ed)
  - Breaks internal tests, likely due to the increased memory requirements ([comment](https://github.com/pytorch/pytorch/pull/120925#issuecomment-1983875400))
- [Revert "[export] Serialize union fields with single entry dict. (#121263)"](https://github.com/pytorch/pytorch/commit/23fb37fa413d03f715a28b44c295bdf3e851f46a)
  - A large number of inductor benchmarking jobs failing starting this PR. See for details: https://hud.pytorch.org/pytorch/pytorch/commit/7feabe9b73e6ba7724b62ea91df27049defdf378 ([comment](https://github.com/pytorch/pytorch/pull/121263#issuecomment-1981680049))
- [Revert "add int4 packed gemm support on CPU device (#117475)"](https://github.com/pytorch/pytorch/commit/0c07c0c15f6c3d3de1a54c523cd6e46b7b89786b)
  - fails meta-internal tests ([comment](https://github.com/pytorch/pytorch/pull/117475#issuecomment-1977474686))
- [Revert "add int8 packed gemm support on CPU device (#118056)"](https://github.com/pytorch/pytorch/commit/a98c17edc75f18fb129f9f488f7757abf0717130)
  - breaks internal builds ([comment](https://github.com/pytorch/pytorch/pull/118056#issuecomment-1977368720))
- [Revert "delete useless cast_outputs call in unary_op_impl_float_out (#120486)"](https://github.com/pytorch/pytorch/commit/9ff65d56a5629e8d981e1bc6bfe051ea55a2e300)
  - Fails meta internal tests ([comment](https://github.com/pytorch/pytorch/pull/120486#issuecomment-1977343125))

### Ignored Signal (1)

- [Revert "[nit][DCP][DSD] Remove Unused Variables in test_state_dict.py (#121204)"](https://github.com/pytorch/pytorch/commit/0f3f4f553421ab9660a8a488c3647b1a5b4e2a87)
  - Sorry for reverting your PR, but the failure looks legit ([comment](https://github.com/pytorch/pytorch/pull/121204#issuecomment-1986252526))

### Not through pytorchbot (1)

- [Revert "[fake_impls] Fix seed/offset device for attention kernels (#120839)" (#121447)](https://github.com/pytorch/pytorch/commit/0f8c9acc29462452814aacc5230f3380f4d8d28e)

### No Signal (5)

- [Revert "Add CUTLASS kernel as choice for _int_mm() Inductor autotuning (#119685)"](https://github.com/pytorch/pytorch/commit/cf9742371ca5150bec2062b1821eefcc5355e475)
  - Sorry for reverting your change, but it is crashing on ROCm https://hud.pytorch.org/pytorch/pytorch/commit/752d164b2f0d401042de4a75f36f7e84bae91daa ([comment](https://github.com/pytorch/pytorch/pull/119685#issuecomment-1986773384))
- [Revert "CI sanity check test for env vars (#120519)"](https://github.com/pytorch/pytorch/commit/2c2d6ce51565642747fec169cdb14ae904359e98)
  - broken on slow https://hud.pytorch.org/pytorch/pytorch/commit/d27509c384c9847cd2ac1f5d63ec143704b50591 https://github.com/pytorch/pytorch/actions/runs/8208843198/job/22453617568 ([comment](https://github.com/pytorch/pytorch/pull/120519#issuecomment-1986480624))
- [Revert "[Inductor] Add support for NEON ISA in the Inductor C++ backend (#105590)"](https://github.com/pytorch/pytorch/commit/e0c534fe02c5d9dec94504f7881cced2bda99604)
  - https://github.com/pytorch/pytorch/issues/121288#issuecomment-1981980699 ([comment](https://github.com/pytorch/pytorch/pull/105590#issuecomment-1984745827))
- [Revert "Update Triton (#119457)"](https://github.com/pytorch/pytorch/commit/3381f282c35b61ca991eb84c0e938667244cbc7a)
  - Sorry for reverting your change but it is failing test_triton_kernels in trunk https://hud.pytorch.org/pytorch/pytorch/commit/d49864f6a526d3def25f8da2fa9b8815b3347b9d ([comment](https://github.com/pytorch/pytorch/pull/119457#issuecomment-1977792634))
- [Revert "[ATen][CUDA][CUBLAS] cublasLtMatmul increase workspace_size (#120925)"](https://github.com/pytorch/pytorch/commit/70c23a51ac2ce418383f22aa6dc54a19f7b1fe17)
  - broke inductor models and caused accuracy regression on nightly dashboard https://hud.pytorch.org/pytorch/pytorch/commit/0a38a6ac8046e4d3f9cfaba86b7ec6517038646f https://github.com/pytorch/pytorch/actions/runs/8118465367/job/22193590228 ([comment](https://github.com/pytorch/pytorch/pull/120925#issuecomment-1977556485))

### Weird (3)

- [Revert "Fix round robin sharding (#121022)"](https://github.com/pytorch/pytorch/commit/9eb8fae02d9fa1bf1e49a21feafb63dfbc509aa8)
  - made sharding really uneven ([comment](https://github.com/pytorch/pytorch/pull/121022#issuecomment-1986552662))
- [Revert "Batch Norm Consolidation (#116092)"](https://github.com/pytorch/pytorch/commit/b529c19bdf5c5bf381eac493ebf2eb1fbd91da6e)
  - broke ROCm, PR signal was clean but trunk was not, the merge should have been blocked but wasn't ([comment](https://github.com/pytorch/pytorch/pull/116092#issuecomment-1981373237))
- [Revert "[XPU][Profiler] Add Logic To The Profiler For Processing XPU-backend Data (#120185)"](https://github.com/pytorch/pytorch/commit/8087912622fc02c866d48bb07a4f46aed91a24e1)
  - This PR contains a list search in '_parse_kineto_events()' that can lead to very high cost of running this post trace, training jobs getting stuck for mins ([comment](https://github.com/pytorch/pytorch/pull/120185#issuecomment-1980180774))
