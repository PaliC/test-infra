{"path":"/Users/sahanp/test-infra/aws/lambda/log-classifier/src/network.rs","line":1,"char":1,"code":"RUSTFMT","severity":"warning","name":"format","description":"See https://github.com/rust-lang/rustfmt#tips","original":"//! Various utilities for interacting with the external world.\nuse anyhow::{Context, Result};\nuse aws_sdk_dynamodb as dynamodb;\nuse aws_sdk_s3 as s3;\nuse aws_sdk_s3::types::ByteStream;\nuse bytes::buf::Buf;\nuse bytes::Bytes;\nuse dynamodb::model::{AttributeAction, AttributeValueUpdate};\nuse flate2::read::GzDecoder;\nuse serde_dynamo::aws_sdk_dynamodb_0_18::to_attribute_value;\nuse std::io::Read;\nuse tracing::info;\n\nuse crate::rule_match::SerializedMatch;\n\nstatic BUCKET_NAME: &str = \"ossci-raw-job-status\";\n\n/// Creates an S3 client instance preconfigured with the right credentials/region.\npub async fn get_s3_client() -> s3::Client {\n    let config = aws_config::from_env().region(\"us-east-1\").load().await;\n    s3::Client::new(&config)\n}\n\npub async fn get_dynamo_client() -> dynamodb::Client {\n    let config = aws_config::load_from_env().await;\n    dynamodb::Client::new(&config)\n}\n\n/// Download a log for `job_id` from S3.\npub async fn download_log(client: &s3::Client, repo: &str, job_id: usize) -> Result<String> {\n    let key = match repo {\n       \"pytorch/pytorch\" => format!(\"log/{}\", job_id),\n       _ => format!(\"log/{}/{}\", repo, job_id)\n    };\n    let resp = client\n        .get_object()\n        .bucket(BUCKET_NAME)\n        .key(key)\n        .send()\n        .await?;\n\n    let data = resp.body.collect().await?;\n    let mut decoder = GzDecoder::new(data.reader());\n    let mut raw_log = String::new();\n    decoder\n        .read_to_string(&mut raw_log)\n        .context(\"failed to decompress log\")?;\n    Ok(raw_log)\n}\n\n/// Upload a classification for `job_id` to S3. `body` should be a serialized\n/// instance of `SerializedMatch`.\npub async fn upload_classification_s3(\n    client: &s3::Client,\n    job_id: usize,\n    body: String,\n) -> Result<()> {\n    client\n        .put_object()\n        .bucket(BUCKET_NAME)\n        .key(format!(\"classification/{job_id}\"))\n        .content_type(\"application/json\")\n        .body(ByteStream::from(Bytes::from(body)))\n        .send()\n        .await?;\n    info!(\"SUCCESS upload classification to s3 for job {}\", job_id);\n    Ok(())\n}\n\n/// Mutates the DynamoDB object for `job_id` to include the `SerializedMatch`.\npub async fn upload_classification_dynamo(\n    client: &dynamodb::Client,\n    repo: &str,\n    job_id: usize,\n    best_match: &SerializedMatch,\n) -> Result<()> {\n    let update = AttributeValueUpdate::builder()\n        .action(AttributeAction::Put)\n        .value(to_attribute_value(best_match)?)\n        .build();\n    client\n        .update_item()\n        .table_name(\"torchci-workflow-job\")\n        .key(\n            \"dynamoKey\",\n            to_attribute_value(format!(\"{}/{}\", repo, job_id))?,\n        )\n        .attribute_updates(\"torchci_classification\", update)\n        .send()\n        .await?;\n    info!(\"SUCCESS upload classification to dynamo for job {}\", job_id);\n    Ok(())\n}\n","replacement":"//! Various utilities for interacting with the external world.\nuse anyhow::{Context, Result};\nuse aws_sdk_dynamodb as dynamodb;\nuse aws_sdk_s3 as s3;\nuse aws_sdk_s3::types::ByteStream;\nuse bytes::buf::Buf;\nuse bytes::Bytes;\nuse dynamodb::model::{AttributeAction, AttributeValueUpdate};\nuse flate2::read::GzDecoder;\nuse serde_dynamo::aws_sdk_dynamodb_0_18::to_attribute_value;\nuse std::io::Read;\nuse tracing::info;\n\nuse crate::rule_match::SerializedMatch;\n\nstatic BUCKET_NAME: &str = \"ossci-raw-job-status\";\n\n/// Creates an S3 client instance preconfigured with the right credentials/region.\npub async fn get_s3_client() -> s3::Client {\n    let config = aws_config::from_env().region(\"us-east-1\").load().await;\n    s3::Client::new(&config)\n}\n\npub async fn get_dynamo_client() -> dynamodb::Client {\n    let config = aws_config::load_from_env().await;\n    dynamodb::Client::new(&config)\n}\n\n/// Download a log for `job_id` from S3.\npub async fn download_log(client: &s3::Client, repo: &str, job_id: usize) -> Result<String> {\n    let key = match repo {\n        \"pytorch/pytorch\" => format!(\"log/{}\", job_id),\n        _ => format!(\"log/{}/{}\", repo, job_id),\n    };\n    let resp = client\n        .get_object()\n        .bucket(BUCKET_NAME)\n        .key(key)\n        .send()\n        .await?;\n\n    let data = resp.body.collect().await?;\n    let mut decoder = GzDecoder::new(data.reader());\n    let mut raw_log = String::new();\n    decoder\n        .read_to_string(&mut raw_log)\n        .context(\"failed to decompress log\")?;\n    Ok(raw_log)\n}\n\n/// Upload a classification for `job_id` to S3. `body` should be a serialized\n/// instance of `SerializedMatch`.\npub async fn upload_classification_s3(\n    client: &s3::Client,\n    job_id: usize,\n    body: String,\n) -> Result<()> {\n    client\n        .put_object()\n        .bucket(BUCKET_NAME)\n        .key(format!(\"classification/{job_id}\"))\n        .content_type(\"application/json\")\n        .body(ByteStream::from(Bytes::from(body)))\n        .send()\n        .await?;\n    info!(\"SUCCESS upload classification to s3 for job {}\", job_id);\n    Ok(())\n}\n\n/// Mutates the DynamoDB object for `job_id` to include the `SerializedMatch`.\npub async fn upload_classification_dynamo(\n    client: &dynamodb::Client,\n    repo: &str,\n    job_id: usize,\n    best_match: &SerializedMatch,\n) -> Result<()> {\n    let update = AttributeValueUpdate::builder()\n        .action(AttributeAction::Put)\n        .value(to_attribute_value(best_match)?)\n        .build();\n    client\n        .update_item()\n        .table_name(\"torchci-workflow-job\")\n        .key(\n            \"dynamoKey\",\n            to_attribute_value(format!(\"{}/{}\", repo, job_id))?,\n        )\n        .attribute_updates(\"torchci_classification\", update)\n        .send()\n        .await?;\n    info!(\"SUCCESS upload classification to dynamo for job {}\", job_id);\n    Ok(())\n}\n"}
{"path":"/Users/sahanp/test-infra/aws/lambda/log-classifier/src/main.rs","line":1,"char":1,"code":"RUSTFMT","severity":"warning","name":"format","description":"See https://github.com/rust-lang/rustfmt#tips","original":"use lambda_http::{run, service_fn, Body, Error, IntoResponse, Request, RequestExt, Response};\n\nuse anyhow::Result;\nuse std::time::Instant;\nuse tracing::info;\n\nuse log_classifier::engine::evaluate_ruleset;\nuse log_classifier::log::Log;\nuse log_classifier::network::{\n    download_log, get_dynamo_client, get_s3_client, upload_classification_dynamo,\n};\nuse log_classifier::rule::RuleSet;\nuse log_classifier::rule_match::SerializedMatch;\n\nstruct ShouldWriteDynamo(bool);\n\nasync fn handle(job_id: usize, repo: &str, should_write_dynamo: ShouldWriteDynamo) -> Result<String> {\n    let client = get_s3_client().await;\n    // Download the log from S3.\n    let start = Instant::now();\n    let raw_log = download_log(&client, repo, job_id).await?;\n    info!(\"download: {:?}\", start.elapsed());\n\n    // Do some preprocessing.\n    let start = Instant::now();\n    let log = Log::new(raw_log);\n    info!(\"preproc: {:?}\", start.elapsed());\n\n    // Run the matching\n    let start = Instant::now();\n    let ruleset = RuleSet::new_from_config();\n    let maybe_match = evaluate_ruleset(&ruleset, &log);\n    info!(\"evaluate: {:?}\", start.elapsed());\n\n    match maybe_match {\n        Some(best_match) => {\n            let match_json = SerializedMatch::new(&best_match, &log);\n            let body = serde_json::to_string_pretty(&match_json)?;\n            info!(\"match: {}\", body);\n            if should_write_dynamo.0 {\n                let client = get_dynamo_client().await;\n                upload_classification_dynamo(&client, repo, job_id, &match_json).await?;\n            }\n            Ok(body)\n        }\n        None => {\n            info!(\"no match found for {}\", job_id);\n            Ok(\"No match found\".into())\n        }\n    }\n}\n\nasync fn function_handler(event: Request) -> Result<Response<Body>, Error> {\n    // Extract some useful information from the request\n    let query_string_parameters = event.query_string_parameters();\n    Ok(match query_string_parameters.first(\"job_id\") {\n        Some(job_id) => {\n            let job_id = job_id.parse::<usize>()?;\n            let repo = query_string_parameters.first(\"repo\").unwrap_or_else(|| \"pytorch/pytorch\");\n            handle(job_id, repo, ShouldWriteDynamo(true))\n                .await?\n                .into_response()\n                .await\n        }\n\n        _ => Response::builder()\n            .status(400)\n            .body(\"no job id provided\".into())\n            .expect(\"failed to render response\"),\n    })\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n    use log_classifier::engine::evaluate_rule;\n    use log_classifier::rule::Rule;\n    use regex::Regex;\n\n    #[test]\n    fn basic_evaluate_rule() {\n        let rule = Rule {\n            name: \"test\".into(),\n            pattern: r\"^test\".parse().unwrap(),\n            priority: 100,\n        };\n\n        let log = Log::new(\"test foo\".into());\n        let match_ = evaluate_rule(&rule, &log);\n        assert_eq!(match_.unwrap().line_number, 1);\n    }\n\n    #[test]\n    fn escape_codes_are_stripped() {\n        let mut ruleset = RuleSet::new();\n        ruleset.add(\"foo\", r\"^test foo\");\n        let log = Log::new(\n            \"\\\n            2022-08-26T17:16:41.9362224Z \\x1b[93;41mtest\\x1b[0m foo\\n\\\n            2022-08-26T17:16:41.9362224Z lol!lol\\n\\\n            \"\n            .into(),\n        );\n        let match_ = evaluate_ruleset(&ruleset, &log).unwrap();\n        assert_eq!(match_.line_number, 1);\n        assert_eq!(match_.rule.name, \"foo\");\n    }\n\n    #[test]\n    fn timestamp_is_stripped() {\n        let mut ruleset = RuleSet::new();\n        ruleset.add(\"foo\", r\"^test\");\n        let log = Log::new(\n            \"\\\n            2022-08-26T17:16:41.9362224Z test foo\\n\\\n            2022-08-26T17:16:41.9362224Z lol!lol\\n\\\n            \"\n            .into(),\n        );\n        let match_ = evaluate_ruleset(&ruleset, &log).unwrap();\n        assert_eq!(match_.line_number, 1);\n        assert_eq!(match_.rule.name, \"foo\");\n    }\n\n    #[test]\n    fn evaluate_rulset_respects_priority() {\n        let mut ruleset = RuleSet::new();\n        ruleset.add(\"higher priority\", r\"^lol!\");\n        ruleset.add(\"lower priority\", r\"^test\");\n        let log = Log::new(\n            \"\\\n            test foo\\n\\\n            lol!lol\\n\\\n            \"\n            .into(),\n        );\n        let match_ = evaluate_ruleset(&ruleset, &log).unwrap();\n        assert_eq!(match_.line_number, 2);\n        assert_eq!(match_.rule.name, \"higher priority\");\n    }\n\n    #[test]\n    fn ignore_skips_match() {\n        let mut ruleset = RuleSet::new();\n        ruleset.add(\"test\", r\"^test\");\n        let log = Log::new(\n            \"\\\n            =================== sccache compilation log ===================\\n\\\n            testt\\n\\\n            =========== If your build fails, please take a look at the log above for possible reasons ===========\\n\\\n            \"\n                .into(),\n        );\n        let match_ = evaluate_ruleset(&ruleset, &log);\n        assert!(match_.is_none());\n    }\n\n    #[test]\n    fn match_before_ignore() {\n        let mut ruleset = RuleSet::new();\n        ruleset.add(\"test\", r\"^test\");\n        let log = Log::new(\n            \"\\\n            testt\\n\\\n            =================== sccache compilation log ===================\\n\\\n            =========== If your build fails, please take a look at the log above for possible reasons ===========\\n\\\n            \"\n                .into(),\n        );\n        let match_ = evaluate_ruleset(&ruleset, &log).unwrap();\n        assert_eq!(match_.line_number, 1);\n    }\n\n    #[test]\n    fn match_after_ignore() {\n        let mut ruleset = RuleSet::new();\n        ruleset.add(\"test\", r\"^test\");\n        let log = Log::new(\n            \"\\\n            =================== sccache compilation log ===================\\n\\\n            =========== If your build fails, please take a look at the log above for possible reasons ===========\\n\\\n            testt\\n\\\n            \"\n                .into(),\n        );\n        let match_ = evaluate_ruleset(&ruleset, &log).unwrap();\n        assert_eq!(match_.line_number, 3);\n    }\n\n    #[test]\n    fn later_match_wins() {\n        let mut ruleset = RuleSet::new();\n        ruleset.add(\"test\", r\"^test\");\n        let log = Log::new(\n            \"\\\n            testt\\n\\\n            testt\\n\\\n            \"\n            .into(),\n        );\n        let match_ = evaluate_ruleset(&ruleset, &log).unwrap();\n        assert_eq!(match_.line_number, 2);\n    }\n\n    #[test]\n    fn rules_compile_correctly() {\n        // Try re-compiling the rules to make sure there are no invalid regexes.\n        let ruleset = RuleSet::new_from_config();\n        for rule in &ruleset.rules {\n            Regex::new(rule.pattern.as_str()).unwrap();\n        }\n    }\n\n    // Actually download some id.\n    // #[tokio::test]\n    // async fn test_real() {\n    //    let foo = handle(12421522599, \"pytorch/vision\", ShouldWriteDynamo(false)).await;\n    //    panic!(\"{:#?}\", foo);\n    // }\n}\n","replacement":"use lambda_http::{run, service_fn, Body, Error, IntoResponse, Request, RequestExt, Response};\n\nuse anyhow::Result;\nuse std::time::Instant;\nuse tracing::info;\n\nuse log_classifier::engine::evaluate_ruleset;\nuse log_classifier::log::Log;\nuse log_classifier::network::{\n    download_log, get_dynamo_client, get_s3_client, upload_classification_dynamo,\n};\nuse log_classifier::rule::RuleSet;\nuse log_classifier::rule_match::SerializedMatch;\n\nstruct ShouldWriteDynamo(bool);\n\nasync fn handle(\n    job_id: usize,\n    repo: &str,\n    should_write_dynamo: ShouldWriteDynamo,\n) -> Result<String> {\n    let client = get_s3_client().await;\n    // Download the log from S3.\n    let start = Instant::now();\n    let raw_log = download_log(&client, repo, job_id).await?;\n    info!(\"download: {:?}\", start.elapsed());\n\n    // Do some preprocessing.\n    let start = Instant::now();\n    let log = Log::new(raw_log);\n    info!(\"preproc: {:?}\", start.elapsed());\n\n    // Run the matching\n    let start = Instant::now();\n    let ruleset = RuleSet::new_from_config();\n    let maybe_match = evaluate_ruleset(&ruleset, &log);\n    info!(\"evaluate: {:?}\", start.elapsed());\n\n    match maybe_match {\n        Some(best_match) => {\n            let match_json = SerializedMatch::new(&best_match, &log);\n            let body = serde_json::to_string_pretty(&match_json)?;\n            info!(\"match: {}\", body);\n            if should_write_dynamo.0 {\n                let client = get_dynamo_client().await;\n                upload_classification_dynamo(&client, repo, job_id, &match_json).await?;\n            }\n            Ok(body)\n        }\n        None => {\n            info!(\"no match found for {}\", job_id);\n            Ok(\"No match found\".into())\n        }\n    }\n}\n\nasync fn function_handler(event: Request) -> Result<Response<Body>, Error> {\n    // Extract some useful information from the request\n    let query_string_parameters = event.query_string_parameters();\n    Ok(match query_string_parameters.first(\"job_id\") {\n        Some(job_id) => {\n            let job_id = job_id.parse::<usize>()?;\n            let repo = query_string_parameters\n                .first(\"repo\")\n                .unwrap_or_else(|| \"pytorch/pytorch\");\n            handle(job_id, repo, ShouldWriteDynamo(true))\n                .await?\n                .into_response()\n                .await\n        }\n\n        _ => Response::builder()\n            .status(400)\n            .body(\"no job id provided\".into())\n            .expect(\"failed to render response\"),\n    })\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\n    tracing_subscriber::fmt()\n        .with_max_level(tracing::Level::INFO)\n        // disabling time is handy because CloudWatch will add the ingestion time.\n        .without_time()\n        .init();\n\n    run(service_fn(function_handler)).await\n}\n\n#[cfg(test)]\nmod test {\n    use super::*;\n    use log_classifier::engine::evaluate_rule;\n    use log_classifier::rule::Rule;\n    use regex::Regex;\n\n    #[test]\n    fn basic_evaluate_rule() {\n        let rule = Rule {\n            name: \"test\".into(),\n            pattern: r\"^test\".parse().unwrap(),\n            priority: 100,\n        };\n\n        let log = Log::new(\"test foo\".into());\n        let match_ = evaluate_rule(&rule, &log);\n        assert_eq!(match_.unwrap().line_number, 1);\n    }\n\n    #[test]\n    fn escape_codes_are_stripped() {\n        let mut ruleset = RuleSet::new();\n        ruleset.add(\"foo\", r\"^test foo\");\n        let log = Log::new(\n            \"\\\n            2022-08-26T17:16:41.9362224Z \\x1b[93;41mtest\\x1b[0m foo\\n\\\n            2022-08-26T17:16:41.9362224Z lol!lol\\n\\\n            \"\n            .into(),\n        );\n        let match_ = evaluate_ruleset(&ruleset, &log).unwrap();\n        assert_eq!(match_.line_number, 1);\n        assert_eq!(match_.rule.name, \"foo\");\n    }\n\n    #[test]\n    fn timestamp_is_stripped() {\n        let mut ruleset = RuleSet::new();\n        ruleset.add(\"foo\", r\"^test\");\n        let log = Log::new(\n            \"\\\n            2022-08-26T17:16:41.9362224Z test foo\\n\\\n            2022-08-26T17:16:41.9362224Z lol!lol\\n\\\n            \"\n            .into(),\n        );\n        let match_ = evaluate_ruleset(&ruleset, &log).unwrap();\n        assert_eq!(match_.line_number, 1);\n        assert_eq!(match_.rule.name, \"foo\");\n    }\n\n    #[test]\n    fn evaluate_rulset_respects_priority() {\n        let mut ruleset = RuleSet::new();\n        ruleset.add(\"higher priority\", r\"^lol!\");\n        ruleset.add(\"lower priority\", r\"^test\");\n        let log = Log::new(\n            \"\\\n            test foo\\n\\\n            lol!lol\\n\\\n            \"\n            .into(),\n        );\n        let match_ = evaluate_ruleset(&ruleset, &log).unwrap();\n        assert_eq!(match_.line_number, 2);\n        assert_eq!(match_.rule.name, \"higher priority\");\n    }\n\n    #[test]\n    fn ignore_skips_match() {\n        let mut ruleset = RuleSet::new();\n        ruleset.add(\"test\", r\"^test\");\n        let log = Log::new(\n            \"\\\n            =================== sccache compilation log ===================\\n\\\n            testt\\n\\\n            =========== If your build fails, please take a look at the log above for possible reasons ===========\\n\\\n            \"\n                .into(),\n        );\n        let match_ = evaluate_ruleset(&ruleset, &log);\n        assert!(match_.is_none());\n    }\n\n    #[test]\n    fn match_before_ignore() {\n        let mut ruleset = RuleSet::new();\n        ruleset.add(\"test\", r\"^test\");\n        let log = Log::new(\n            \"\\\n            testt\\n\\\n            =================== sccache compilation log ===================\\n\\\n            =========== If your build fails, please take a look at the log above for possible reasons ===========\\n\\\n            \"\n                .into(),\n        );\n        let match_ = evaluate_ruleset(&ruleset, &log).unwrap();\n        assert_eq!(match_.line_number, 1);\n    }\n\n    #[test]\n    fn match_after_ignore() {\n        let mut ruleset = RuleSet::new();\n        ruleset.add(\"test\", r\"^test\");\n        let log = Log::new(\n            \"\\\n            =================== sccache compilation log ===================\\n\\\n            =========== If your build fails, please take a look at the log above for possible reasons ===========\\n\\\n            testt\\n\\\n            \"\n                .into(),\n        );\n        let match_ = evaluate_ruleset(&ruleset, &log).unwrap();\n        assert_eq!(match_.line_number, 3);\n    }\n\n    #[test]\n    fn later_match_wins() {\n        let mut ruleset = RuleSet::new();\n        ruleset.add(\"test\", r\"^test\");\n        let log = Log::new(\n            \"\\\n            testt\\n\\\n            testt\\n\\\n            \"\n            .into(),\n        );\n        let match_ = evaluate_ruleset(&ruleset, &log).unwrap();\n        assert_eq!(match_.line_number, 2);\n    }\n\n    #[test]\n    fn rules_compile_correctly() {\n        // Try re-compiling the rules to make sure there are no invalid regexes.\n        let ruleset = RuleSet::new_from_config();\n        for rule in &ruleset.rules {\n            Regex::new(rule.pattern.as_str()).unwrap();\n        }\n    }\n\n    // Actually download some id.\n    // #[tokio::test]\n    // async fn test_real() {\n    //    let foo = handle(12421522599, \"pytorch/vision\", ShouldWriteDynamo(false)).await;\n    //    panic!(\"{:#?}\", foo);\n    // }\n}\n"}
